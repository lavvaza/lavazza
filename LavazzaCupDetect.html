<html>


<head>

  <!-- <meta name="viewport" content="initial-scale=1, maximum-scale=1"> -->

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <script src="resources/jquery.min.js"></script>
  <script src="resources/bootstrap.min.js"></script>

  <link type="text/css" rel="stylesheet" href="resources/bootstrap.min.css">


  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css"
    integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w=="
    crossorigin="anonymous" referrerpolicy="no-referrer" />
  <script src="//cdn.rawgit.com/mrdoob/three.js/master/build/three.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
  <link type="text/css" rel="stylesheet" href="./resources/css/common.css">
  
  <script src="./resources/js/utils.js"></script>

  <link rel="stylesheet" href="./resources/css/LavazzaCupDetect.css">
  <style>

    .arrow_icon {
      height: 45px;
    }

    .image_main {
      position: absolute;
      left: 0;
      right: 0;
      bottom: 0;
      top: 0;
      height: 100%;
      width: 100%;
      text-align: center;
      background: transparent;

    }

    .image {
      height: 100%;
      width: 100%;
      background: transparent;
    }


    #footer_section {
      position: absolute;
      left: 0;
      right: 0;
      bottom: 25px;
      top: unset;
      text-align: center;
      height: 65px;
      display: block;
    }

    .instruction_text
    {
      width: auto;
      padding: 12px;
      color: #342012;
      font-weight: bold;
      font-size: 14px;
      background: #e7ddbe;
      margin: 0 10px;
      border-radius: 10px;
      height: 100%;
    }

		.instruction_text_content
		{
			width: 80%;
			float: left;
		}

		#confirm_btn
		{
			float: right;
		}
  </style>
</head>

<body>

  <img class="home_icon" src="./resources/images/home.png" onclick="go_to_home()">

  <div id="title_intro">
    <!--<img class="d-block w-100 " src="./resources/images/cup1.jpg " alt="First slide ">-->
    <div class="over_lay">
      <div class="question_section">
        <h6 class="main_title1"></h6>
        <h2 class="main_title2"></h2>
      </div>
    </div>
  </div>


  <div id="cup_detect_section">

  </div>



  <canvas id="c"></canvas>
  <video id="video" style="display:none" autoplay playsinline></video>
  

  <div id="footer_section">
    <div class="instruction_text" id="confirmtion_btn_id">
			<span class="instruction_text_content">
				CENTRA LA TAZZINA DAVANTI A TE <br>
        CON LA SAGOMA SULLO SCHERMO
			</span>
			<img class="arrow_icon" src="./resources/images/cell.png" 
			id="confirm_btn">
		</div>
  </div>

  <span id="span1" class="labelspan"></span>
  <script type="module">
    import * as THREE from 'https://threejsfundamentals.org/threejs/resources/threejs/r127/build/three.module.js';
    import { ARButton } from './jsm/webxr/ARButton.js';

    const canvas = document.querySelector('#c');
    const renderer = new THREE.WebGLRenderer({ canvas });
    var video;
    const fov = 75;
    const aspect = 2;  // the canvas default
    const near = 0.1;
    const far = 5;
    const camera = new THREE.PerspectiveCamera(fov, aspect, near, far);
    camera.position.z = 2;
    let model_TM, labelContainer, maxPredictions;
    video = document.getElementById('video');
    var texture = new THREE.VideoTexture(video);

    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
      var constraints = { video: { width: 1040, height: 620, facingMode: 'environment' } };
      navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
        // apply the stream to the video element used in the texture
        video.srcObject = stream;
        video.play();
      }).catch(function (error) {
        console.error('Unable to access the camera/webcam.', error);
        scene.background = new THREE.Color("rgb(179, 179, 179)");
      });
    }
    else {
      console.error('MediaDevices interface not available.');
    }


    const scene = new THREE.Scene();
    scene.background = texture;


    const color = 0xFFFFFF;
    const intensity = 1;
    const light = new THREE.DirectionalLight(color, intensity);
    light.position.set(-1, 2, 4);
    scene.add(light);

    const URL = "./resources/trained/";

    function render() {
      if (resizeRendererToDisplaySize(renderer)) {
        const canvas = renderer.domElement;
        camera.aspect = canvas.clientWidth / canvas.clientHeight;
        camera.updateProjectionMatrix();
      }
      renderer.render(scene, camera);
    }

    function animate(time) {
      render();
      requestAnimationFrame(animate);

    }
    requestAnimationFrame(animate);

    function movenext() 
    {
      window.location.href = "roast.html?blend=" + BLEND;
    }

    function resizeRendererToDisplaySize(renderer) {
      const canvas = renderer.domElement;
      const width = canvas.clientWidth;
      const height = canvas.clientHeight;
      const needResize = canvas.width !== width || canvas.height !== height;
      if (needResize) {
        renderer.setSize(width, height, false);
      }
      return needResize;
    }


    //TM code starts
    // Load the image model and setup the webcam
    async function init_TM() {
      const modelURL = URL + "model.json";
      const metadataURL = URL + "metadata.json";


      // load the model and metadata
      // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
      // or files from your local hard drive
      // Note: the pose library adds "tmImage" object to your window (window.tmImage)
      model_TM = await tmImage.load(modelURL, metadataURL);
      maxPredictions = model_TM.getTotalClasses();
      var classname = "";
      const prediction = await model_TM.predict(video);
      for (let i = 0; i < maxPredictions; i++) 
      {
        if (prediction[i].probability.toFixed(2) > 0.89) {
          classname = prediction[i].className;
          //break;
        }

      }

      if (classname == 'Lavazza Cup') 
      {
          movenext();
      }
      else if (classname == 'Other Cup') 
      {
        // window.location.href = "LavazzaObjects.html";
        //window.location.href = "roast.html?blend=alteco";
        // document.getElementById("span1").innerHTML = "Place the Lavazza Cup for detection";
        //document.getElementById("footer").style.display = "block";
      }
      else if (classname == 'No Cup') 
      {
        // document.getElementById("span1").innerHTML = "Place the Cup for detection";
      }
    }


    
    setInterval(function () {
      init_TM();
    }, 4 * 1000)

  </script>

  <script>

    setTimeout(function () {
      document.getElementById("title_intro").style.display = "none";
      document.getElementById("cup_detect_section").style.display = "block";
    }, 3 * 1000)

  </script>
</body>

</html>